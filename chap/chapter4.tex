\chapter{Latency Reduction\label{chap4}}

The previous chapter demonstrated virtual interrupt latency for real-time guest is significantly larger than in native setup.
Recent extensions to x86 hardware-assisted virtualization support virtualization of local interrupt controller (APIC-v) 
that enables hypervisor to minimize its involvement. Furthermore, it allows direct interrupt injection to the guest for
devices that are owned by guests. It also enables virtualization of translation lookaside buffers (TLBs) by supporting virtual
process identifiers (VPIDs). 
The hypervisor can use VPIDs to isolate address translation information of different guests from each other and from the hypervisor.
Intel Cache Allocation Technology addresses contention of shared LLC that enables hypervisor to partition shared cache
among the guests to avoid cache pollution.
This chapter presents results of using these hardware mechanisms to reduce interrupt latencies for real-time guest.
Following sections provide details of using each mechanism separately and records improvements in the interrupt latency.


\section{Direct Interrupt Injection}
Direct interrupt injection (DII) mechanism allows guest operating system to receive interrupts from 
external devices without hypervisor involvement.
APIC virtualization allows the hypervisor to deliver virtual interrupts directly to the guest code without causing a trap. 
The details of this feature have already been covered in section \ref{sec:dii}.
A brief summary of the mechanism is as follows.
The hypervisor marks a virtual interrupt as a posted interrupt (PI) in posted interrupt-descriptor (PID). 
PID is a data structure allocated by the hypervisor.
It allows hypervisor inform interrupt controller that an interrupt is owned by guest and has to be delivered to guest without hypervisor involvement. 
Posted interrupt mechanism only works when hypervisor uses APIC virtualization to manage guest interrupts. 
Figure \ref{fig-posted-interrupts} demonstrates delivery of a guest interrupt does not require hypervisor involvement if it is marked as PI.
Succeeding sections describe performance evaluation of the real-time guest interrupt when DII is used.

\input{./figures/fig-posted-interrupts}


\subsection{Methodology}
The performance evaluation setup for direct interrupt injection mechanism includes PREEMPT\_RT patched Linux as real-time guest (rt-guest)
and Linux as a general-purpose guest (gp-guest). Each guest is assigned to a separate core and has access to 256MB of RAM. The setup is 
similar to the one described in section \ref{sec:methodology}, rt-guest has direct access to PCIe gpio card capable to generate interrupts. 
Measurement setup is same as described in section \ref{sec:measurement-setup}.
Phidias hypervisor was extended to use direct interrupt mechanism for rt-guest GPIO interrupt.
PID data structure has an outstanding notification (ON) bit that enables DII logic. 
The ON bit is cleared by hardware after injecting a posted interrupt directly to the guest. 
The hypervisor is responsible to set the bit again before the arrival of a posted interrupt if it fails the interrupt is delivered to the hypervisor.
Since external gpio interrupts events are generated at the rate of about $2ms$, hypervisor was informed by causing an intentional exit from interrupt handler to
set ON bit again. The approach is similar to the one used in section \ref{sec:context-switch-overhead}.
The latency reduction is evaluated by measuring worst-case interrupt latency with and without direct interrupt injection mechanism.
It involves generating ten thousand GPIO interrupts and recording latency of each event.

\subsection{Latency Reduction}
\input{./figures/plot-dii}

The latency measurement experiment was repeated for different load conditions on the real-time guest and no load on gp-guest. 
Figure \ref{plot-dii} plots comparison of worst-case and average-case interrupt latencies with and without DII. 
It is clear that direct interrupt injection reduces both worst-case and average-case interrupt latency. 
Best results are produced when the rt-guest is loaded with \mcachepressure{} benchmark. 
Interrupt latency reduced approximately by $33\mu{}s$ with $24.8\%$ improvement.
%%All experiement resutls revealed that direct interrupt injection always reduces interrupt latencies.

%%\input{./figures/fig-pii-worstcase}


\section{Portioning Last Level Cache}
Intel Cache Allocation Technology enables portioning of LLC (L3 cache).
The details of this feature have already been covered in section \ref{sec:cat}.
In short, a set of registers called bitmasks allow the hypervisor to configure isolated or shared cache regions.
A bit in the bitmask register can correspond to a way in a set-associative cache.
A separate register is used to assign a portion of the cache to an application based on an identifier called the class-of-service (CLOS).
The Xeon E5-2600v4 processor used to conduct experiments has 15MB 20-way set-associative shared cache bitmask registers has a length of 20bits. 
It supports up to 15 CLOS identifiers.
Succeeding sections describe the methodology and record results of using cache allocation technique.


\subsection{Methodology}
\input{./figures/fig-vsetup-cat-bitmasks}
The latency reduction is evaluated by measuring worst-case interrupt latency with and without LLC partitioning between the two guests.
The setup includes PREEMPT\_RT patched Linux as real-time guest (rt-guest)
and Linux as a general-purpose guest (gp-guest). 
Each guest is assigned to a separate core and has access to 256MB of RAM.
The setup is similar to the one described in section \ref{sec:methodology}, rt-guest has direct access to PCIe gpio card capable to generate interrupts. 
Measurement setup is same as described in section \ref{sec:measurement-setup}.
Phidias hypervisor is extended to support portioning of L3 cache. 
Figure \ref{fig-vsetup-cat-bitmasks} shows CLOS assignment and bitmask configuration for the test setup.
The cache was divided equally between the two guests. Some part of the cache is kept shared for the shared data such as Phidias core.
The gpio interrupt latency was measured while high memory demands generated by gp-guest. 
The experiments were repeated with and without cache allocation to measure improvement in latency.
A synthetic application was used to generate high memory demands from gp-guest.

\subsection{Latency Reduction}
\input{./figures/plot-cat}
The latency measurement experiment was repeated for different load conditions on rt-guest when gp-guest was executed application large amounts of memory. 
Figure \ref{plot-cat} plots comparison of worst-case and average-case interrupt latencies when LLC is shared and when it is partitioned. 
It is clear that separating real-time guest cache from the other guest improves both worst-case and average-case interrupt response times.
Best results are observed when the rt-guest is loaded with \mforkops{} benchmark. 
Interrupt latency reduced approximately by $21\mu{}s$ with $16.6\%$ improvement.

\section{TLB Partitioning using VPIDs} \label{sec:vtlb-latency-red}
Translation lookaside buffers (TLBs) are used by the processor to cache virtual to physical address translations.
Modern architectures have separate TLBs for instruction and data known as iTLB and dTLB respectively. 
In a virtual environment hypervisor and guest operating system access different virtual address spaces.
Caching translations of both address spaces at same TLB can result in thrashing translations of each other on a context switch. 
Furthermore, when a guest flushes TLB entries, it also flushes cached information for hypervisor address space.
The hypervisor can use TLB partitioning through VPIDs to isolate traffic of its own address space from the guests running in virtual machines.
This section evaluates performance improvement for interrupt response time by using VPIDs.

\subsection{Methodology}
Two guest setup from the previous section is used again, however, this time hypervisor is extended to use VPID mechanism.
The hypervisor assigns a unique process identifier to each guest and emulates TLB flush instructions for the guest based on its VPID.
The guest is oblivious to the VPID mechanism.
Note that performance evaluation is focused on isolating guest translations from hypervisor as both execute on the same core.
Since Phidias hypervisor uses multikernel approach the shared resources are at least used by the hypervisor and the guest.

The latency reduction is evaluated by measuring worst-case interrupt latency with and without TLB partitioning.
The setup includes PREEMPT\_RT patched Linux as real-time guest (rt-guest)
and Linux as a general-purpose guest (gp-guest). 
The setup is similar to the one described in section \ref{sec:methodology}, rt-guest has direct access to PCIe gpio card capable to generate interrupts. 
Measurement setup is same as described in section \ref{sec:measurement-setup}.
The hypervisor was extended to support TLB partitioning. 
It assigns a unique process identifier to each guest and emulates TLB flush instructions for the guest based on VPIDs.

\subsection{Latency Reduction}

\input{./figures/plot-vpid}

The latency measurement experiment was repeated for different load conditions on the real-time guest and no load on gp-guest. 
Figure \ref{plot-vpid} plots comparison of worst-case and average-case interrupt latencies with shared and isolated TLBs for rt-guest and hypervisor. 
Results show that separating guest TLB using VPID mechanism has improved both the worst-case and average-case interrupt latencies.
The average-case interrupt latency has decreased by at least $1.1us$. The worst-case latency has slightly increased with no load condition,
however, it has always decreased with load conditions. 
Best results are produced when the guest is loaded with \mthreadops{} benchmark. 
Interrupt latency reduced by approximately $20u\mu{}s$ with $12.2\%$ improvement.

\section{CAT, DII, and VPID Combined}
This section records improvement in real-time interrupt latency when all latency reduction techniques are combined.
Figure \ref{plot-allopt} plots comparison of average and worst-case interrupt latencies between virtualization 
overhead recorded in previous chapter (section \ref{sec:virtual-overhead}) and latency reduction techniques presented in this chapter.
\input{./figures/plot-allopt}

The worst-case interrupt response time has always improved more than $21\%$ and average-case by more than $39\%$ when latency reduction techniques are deployed.
Best results are produced for \mthreadops{} load when worst-case latency reduced approximately by $43\%$.
The overall improvement with all optimization enabled, look very similar to results for direct interrupt mechanism. 
However, the average and worst-case latency have improved slightly.

Figure \ref{plot-cdf-native-virtual-optimiz} plots CDF of gpio interrupt latency for three different setups: native, virtual with no optimization and virtual with latency reduction techniques. 
CDF plots for rest of the benchmarks are available in Appendix \ref{app:c}.
The interrupt latency is plotted for three different loads, same as in Figure \ref{plot-cdf-native-vs-virtual}.
The comparison of CDFs reveals improved average-case response time and reduced spread compared to virtualization overhead recorded in the previous chapter.

\input{./figures/plot-cdf-native-virtual-optimiz}




